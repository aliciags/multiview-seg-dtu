{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to reproduce all the numeric results in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from pathlib import Path\n",
    "from dataloader import get_dataloader, walk_through_dir\n",
    "from models import SimpleSegmentationModel, SegmentationModel, pretrained_UNet\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataloader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    all_preds = []  # List to store all predictions\n",
    "    all_labels = []  # List to store all ground truth labels\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, masks in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert outputs to binary predictions using a threshold\n",
    "            binary_outputs = (outputs > torch.quantile(outputs, 0.8)).float()\n",
    "\n",
    "            # Flatten the outputs and masks for evaluation\n",
    "            binary_outputs_np = binary_outputs.cpu().numpy().flatten()\n",
    "            masks_np = masks.cpu().numpy().flatten()\n",
    "\n",
    "            # Collect predictions and true labels for metrics calculation\n",
    "            all_preds.extend(binary_outputs_np)\n",
    "            all_labels.extend(masks_np)\n",
    "\n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    \n",
    "    # Ensure that labels and predictions are both binary (0 or 1)\n",
    "    all_preds = [int(x) for x in all_preds]  # Convert predictions to integer binary\n",
    "    all_labels = [int(x) for x in all_labels]  # Convert labels to integer binary\n",
    "\n",
    "    # Compute Precision, Recall, and F1 score\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    # Compute Dice Score\n",
    "    intersection = np.sum(np.array(all_preds) * np.array(all_labels))\n",
    "    dice_score = (2.0 * intersection) / (np.sum(all_preds) + np.sum(all_labels) + 1e-8)\n",
    "\n",
    "    # Compute IoU (Intersection over Union)\n",
    "    union = np.sum((np.array(all_preds) + np.array(all_labels)) > 0)\n",
    "    iou = intersection / (union + 1e-8)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Average Loss on Test Set: {avg_loss:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Dice Score: {dice_score:.4f}\")\n",
    "    print(f\"IoU: {iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/zhome/70/5/14854/nobackup/deeplearningf24/forcebiology/data/\"\n",
    "image_dirs = [data_path + 'brightfield/Alexa488_Fibroblasts_well1_50locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well2_200locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well3_200locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well4_225locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well5_225locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well6_135locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well7_135locations']\n",
    "mask_dir = data_path + 'masks'\n",
    "\n",
    "def set_seed(seed=111):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "mask_transform = data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(channels, pth_model, model_name):\n",
    "    # Get the dataloaders with optional channel selection\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_dataloader(\n",
    "        image_dirs, \n",
    "        mask_dir, \n",
    "        data_transform, \n",
    "        mask_transform, \n",
    "        display_sample=False, \n",
    "        train_percentage=1.0, \n",
    "        channel_indices=channels\n",
    "    )\n",
    "\n",
    "    # Initialize the device\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = \"cpu\"\n",
    "    criterion = nn.BCELoss()\n",
    "    current_directory = os.getcwd()\n",
    "    model_save_path = os.path.join(current_directory, pth_model)\n",
    "\n",
    "    # Load the model\n",
    "    if model_name == \"Simple\":\n",
    "        model = SimpleSegmentationModel().to(device)\n",
    "    elif model_name == \"UNet\":\n",
    "        model = SegmentationModel(channels=len(channels)).to(device)\n",
    "    elif model_name == \"Pretrained\":\n",
    "        model = pretrained_UNet().to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=torch.device('cpu'), weights_only=True))\n",
    "    print(f\"Model {pth_model} loaded successfully.\")\n",
    "\n",
    "    return model, test_dataloader, criterion, device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evaluation for different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inital UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels0_1_2_3_4_5_6_7_8_9_10.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.7551\n",
      "Precision: 0.6175\n",
      "Recall: 0.6930\n",
      "F1 Score: 0.6531\n",
      "Dice Score: 0.6531\n",
      "IoU: 0.4849\n"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.9/tarfile.py:2268: RuntimeWarning: The default behavior of tarfile extraction has been changed to disallow common exploits (including CVE-2007-4559). By default, absolute/parent paths are disallowed and some mode bits are cleared. See https://access.redhat.com/articles/7004769 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model models/segmentation_model_Pretrained.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.3317\n",
      "Precision: 0.5773\n",
      "Recall: 0.6479\n",
      "F1 Score: 0.6105\n",
      "Dice Score: 0.6105\n",
      "IoU: 0.4394\n"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_Pretrained.pth'\n",
    "model_name = 'Pretrained'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on train percentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train20%_channels0_1_2_3_4_5_6_7_8_9_10.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.4475\n",
      "Precision: 0.4971\n",
      "Recall: 0.5579\n",
      "F1 Score: 0.5258\n",
      "Dice Score: 0.5258\n",
      "IoU: 0.3566\n"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train20%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train40%_channels0_1_2_3_4_5_6_7_8_9_10.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.3503\n",
      "Precision: 0.6152\n",
      "Recall: 0.6904\n",
      "F1 Score: 0.6506\n",
      "Dice Score: 0.6506\n",
      "IoU: 0.4822\n"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train40%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train60%_channels0_1_2_3_4_5_6_7_8_9_10.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.3568\n",
      "Precision: 0.6471\n",
      "Recall: 0.7263\n",
      "F1 Score: 0.6844\n",
      "Dice Score: 0.6844\n",
      "IoU: 0.5202\n"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train60%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train80%_channels0_1_2_3_4_5_6_7_8_9_10.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.6034\n",
      "Precision: 0.6050\n",
      "Recall: 0.6790\n",
      "F1 Score: 0.6399\n",
      "Dice Score: 0.6399\n",
      "IoU: 0.4705\n"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train80%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With augmentation and fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels0_1_2_3_4_5_6_7_8_9_10_augmentation_fft.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.3591\n",
      "Precision: 0.5693\n",
      "Recall: 0.6389\n",
      "F1 Score: 0.6021\n",
      "Dice Score: 0.6021\n",
      "IoU: 0.4307\n"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels0_1_2_3_4_5_6_7_8_9_10_augmentation_fft.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With different channels\n",
    "Channels based on GradCAM channel importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels1.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.3376\n",
      "Precision: 0.6490\n",
      "Recall: 0.7285\n",
      "F1 Score: 0.6865\n",
      "Dice Score: 0.6865\n",
      "IoU: 0.5226\n"
     ]
    }
   ],
   "source": [
    "channels = [1]\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels1.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels1_7.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.2780\n",
      "Precision: 0.6493\n",
      "Recall: 0.7288\n",
      "F1 Score: 0.6868\n",
      "Dice Score: 0.6868\n",
      "IoU: 0.5230\n"
     ]
    }
   ],
   "source": [
    "channels = [1, 7]\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels1_7.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels1_7_2_4_3_9_6.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.3865\n",
      "Precision: 0.5583\n",
      "Recall: 0.6266\n",
      "F1 Score: 0.5905\n",
      "Dice Score: 0.5905\n",
      "IoU: 0.4190\n"
     ]
    }
   ],
   "source": [
    "channels = [1, 7, 2, 4, 3, 9, 6]\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels1_7_2_4_3_9_6.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channels chosen based on focal position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels6.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.3760\n",
      "Precision: 0.6025\n",
      "Recall: 0.6762\n",
      "F1 Score: 0.6373\n",
      "Dice Score: 0.6373\n",
      "IoU: 0.4676\n"
     ]
    }
   ],
   "source": [
    "channels = [6]\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels6.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels5_6_7.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.4450\n",
      "Precision: 0.5497\n",
      "Recall: 0.6169\n",
      "F1 Score: 0.5814\n",
      "Dice Score: 0.5814\n",
      "IoU: 0.4098\n"
     ]
    }
   ],
   "source": [
    "channels = [5, 6, 7]\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels5_6_7.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels4_5_6_7_8.pth loaded successfully.\n",
      "Average Loss on Test Set: 1.8912\n",
      "Precision: 0.5622\n",
      "Recall: 0.6310\n",
      "F1 Score: 0.5946\n",
      "Dice Score: 0.5946\n",
      "IoU: 0.4231\n"
     ]
    }
   ],
   "source": [
    "channels = [4, 5, 6, 7, 8]\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels4_5_6_7_8.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels3_4_5_6_7_8_9.pth loaded successfully.\n",
      "Average Loss on Test Set: 0.5919\n",
      "Precision: 0.6254\n",
      "Recall: 0.7019\n",
      "F1 Score: 0.6615\n",
      "Dice Score: 0.6615\n",
      "IoU: 0.4942\n"
     ]
    }
   ],
   "source": [
    "channels = [3, 4, 5, 6, 7, 8, 9]\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels3_4_5_6_7_8_9.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
