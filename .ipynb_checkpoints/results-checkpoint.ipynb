{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to reproduce all the numeric results in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from pathlib import Path\n",
    "from dataloader import get_dataloader, walk_through_dir\n",
    "from models import SimpleSegmentationModel, SegmentationModel, pretrained_UNet\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataloader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    all_preds = []  # List to store all predictions\n",
    "    all_labels = []  # List to store all ground truth labels\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, masks in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert outputs to binary predictions (threshold at 0.5 for binary classification)\n",
    "            binary_outputs = (outputs > 0.5).float()\n",
    "\n",
    "            # Flatten the outputs and masks for evaluation\n",
    "            binary_outputs_np = binary_outputs.cpu().numpy().flatten()\n",
    "            masks_np = masks.cpu().numpy().flatten()\n",
    "\n",
    "            # Collect predictions and true labels for metrics calculation\n",
    "            all_preds.extend(binary_outputs_np)\n",
    "            all_labels.extend(masks_np)\n",
    "\n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    \n",
    "    # Ensure that labels and predictions are both binary (0 or 1)\n",
    "    all_preds = [int(x) for x in all_preds]  # Convert predictions to integer binary\n",
    "    all_labels = [int(x) for x in all_labels]  # Convert labels to integer binary\n",
    "\n",
    "    # Compute Precision, Recall, and F1 score\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    # Compute Dice Score\n",
    "    intersection = np.sum(np.array(all_preds) * np.array(all_labels))\n",
    "    dice_score = (2.0 * intersection) / (np.sum(all_preds) + np.sum(all_labels) + 1e-8)\n",
    "\n",
    "    # Compute IoU (Intersection over Union)\n",
    "    union = np.sum((np.array(all_preds) + np.array(all_labels)) > 0)\n",
    "    iou = intersection / (union + 1e-8)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Average Loss on Test Set: {avg_loss:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Dice Score: {dice_score:.4f}\")\n",
    "    print(f\"IoU: {iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/zhome/70/5/14854/nobackup/deeplearningf24/forcebiology/data/\"\n",
    "image_dirs = [data_path + 'brightfield/Alexa488_Fibroblasts_well1_50locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well2_200locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well3_200locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well4_225locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well5_225locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well6_135locations',\n",
    "                data_path + 'brightfield/Alexa488_Fibroblasts_well7_135locations']\n",
    "mask_dir = data_path + 'masks'\n",
    "\n",
    "def set_seed(seed=111):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "mask_transform = data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(channels pth_model, model_name):\n",
    "    # Get the dataloaders with optional channel selection\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_dataloader(\n",
    "        image_dirs, \n",
    "        mask_dir, \n",
    "        data_transform, \n",
    "        mask_transform, \n",
    "        display_sample=False, \n",
    "        train_percentage=1.0, \n",
    "        channel_indices=channels\n",
    "    )\n",
    "\n",
    "    # Initialize the device\n",
    "    #Â device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = \"cpu\"\n",
    "    criterion = nn.BCELoss()\n",
    "    current_directory = os.getcwd()\n",
    "    model_save_path = os.path.join(current_directory, pth_model)\n",
    "\n",
    "    # Load the model\n",
    "    if model_name == \"Simple\":\n",
    "        model = SimpleSegmentationModel().to(device)\n",
    "    elif model_name == \"UNet\":\n",
    "        model = SegmentationModel(channels=len(channels)).to(device)\n",
    "    elif model_name == \"Pretrained\":\n",
    "        model = pretrained_UNet().to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=torch.device('cpu')))\n",
    "    print(f\"Model {pth_model} loaded successfully.\")\n",
    "\n",
    "    return model, test_dataloader, criterion, device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evaluation for different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inital UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n",
      "Model models/segmentation_model_UNet_train100%_channels0_1_2_3_4_5_6_7_8_9_10.pth loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1066148/1467126935.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path, map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss on Test Set: 0.7551\n",
      "Precision: 0.2806\n",
      "Recall: 0.8834\n",
      "F1 Score: 0.4259\n",
      "Dice Score: 0.4259\n",
      "IoU: 0.2706\n"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "augmentation = False\n",
    "fft = False\n",
    "pth_model = 'models/segmentation_model_UNet_train100%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, augmentation, fft, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the trainset: 889\n",
      "Number of images in the valset: 223\n",
      "Number of images in the testset: 50\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'smp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m pth_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/segmentation_model_Pretrained.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPretrained\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m model, test_dataloader, criterion, device \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpth_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m      9\u001b[0m evaluate_model(model, test_dataloader, criterion, device)\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(channels, augmentation, fft, pth_model, model_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m     model \u001b[38;5;241m=\u001b[39m SegmentationModel(channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(channels))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mpretrained_UNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_save_path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpth_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/multiview-seg-dtu/models.py:106\u001b[0m, in \u001b[0;36mpretrained_UNet\u001b[0;34m(channels)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpretrained_UNet\u001b[39m(channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# Load pretrained U-Net with a ResNet backbone\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     pretrained_unet \u001b[38;5;241m=\u001b[39m \u001b[43msmp\u001b[49m\u001b[38;5;241m.\u001b[39mUnet(\n\u001b[1;32m    107\u001b[0m         encoder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet34\u001b[39m\u001b[38;5;124m\"\u001b[39m,        \u001b[38;5;66;03m# Choose a ResNet backbone (others available)\u001b[39;00m\n\u001b[1;32m    108\u001b[0m         encoder_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m,    \u001b[38;5;66;03m# Use pretrained weights on ImageNet\u001b[39;00m\n\u001b[1;32m    109\u001b[0m         in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,                 \u001b[38;5;66;03m# Placeholder for in_channels, will replace later\u001b[39;00m\n\u001b[1;32m    110\u001b[0m         classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m                      \u001b[38;5;66;03m# Output channels (binary mask)\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Modify the first convolutional layer to accept 11 input channels\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     pretrained_unet\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(\n\u001b[1;32m    115\u001b[0m         in_channels\u001b[38;5;241m=\u001b[39mchannels,               \u001b[38;5;66;03m# From 3 to 11 channels\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m         bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smp' is not defined"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "augmentation = False\n",
    "fft = False\n",
    "pth_model = 'models/segmentation_model_Pretrained.pth'\n",
    "model_name = 'Pretrained'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, augmentation, fft, pth_model, model_name)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on train percentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_model() missing 2 required positional arguments: 'pth_model' and 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m pth_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/segmentation_model_UNet_train20\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_channels0_1_2_3_4_5_6_7_8_9_10.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model, test_dataloader, criterion, device \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpth_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m evaluate_model(model, test_dataloader, criterion, device)\n",
      "\u001b[0;31mTypeError\u001b[0m: run_model() missing 2 required positional arguments: 'pth_model' and 'model_name'"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train20%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_model() missing 2 required positional arguments: 'pth_model' and 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m pth_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/segmentation_model_UNet_train40\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_channels0_1_2_3_4_5_6_7_8_9_10.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model, test_dataloader, criterion, device \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpth_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m evaluate_model(model, test_dataloader, criterion, device)\n",
      "\u001b[0;31mTypeError\u001b[0m: run_model() missing 2 required positional arguments: 'pth_model' and 'model_name'"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train40%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_model() missing 2 required positional arguments: 'pth_model' and 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m pth_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/segmentation_model_UNet_train60\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_channels0_1_2_3_4_5_6_7_8_9_10.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model, test_dataloader, criterion, device \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpth_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m evaluate_model(model, test_dataloader, criterion, device)\n",
      "\u001b[0;31mTypeError\u001b[0m: run_model() missing 2 required positional arguments: 'pth_model' and 'model_name'"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train60%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_model() missing 2 required positional arguments: 'pth_model' and 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m pth_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/segmentation_model_UNet_train80\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_channels0_1_2_3_4_5_6_7_8_9_10.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model, test_dataloader, criterion, device \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpth_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m evaluate_model(model, test_dataloader, criterion, device)\n",
      "\u001b[0;31mTypeError\u001b[0m: run_model() missing 2 required positional arguments: 'pth_model' and 'model_name'"
     ]
    }
   ],
   "source": [
    "channels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "pth_model = 'models/segmentation_model_UNet_train80%_channels0_1_2_3_4_5_6_7_8_9_10.pth'\n",
    "model_name = 'UNet'\n",
    "\n",
    "model, test_dataloader, criterion, device = run_model(channels, pth_model, model_name)\n",
    "evaluate_model(model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With augmentation and fft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
